{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalizing the SAM predictor\n",
    "This code section initalizes the original SAM model and functions that come from the Meta notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 172\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m#Sorting Data\u001b[39;00m\n\u001b[1;32m    171\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/vstor/CSE_MSE_RXF131/lab-staging/mds3/AdvManu/fractography/combined_df.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Loading combined_df\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m combined_df[\u001b[38;5;241m-\u001b[39mcombined_df[\u001b[43mtask\u001b[49m]\u001b[38;5;241m.\u001b[39misna()] \u001b[38;5;66;03m# Filtering out those without the tasked image\u001b[39;00m\n\u001b[1;32m    173\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m combined_df[\u001b[38;5;241m~\u001b[39mcombined_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample#\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCMU11\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;66;03m# Filtering out the unpolished samples\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m#combined_df = combined_df[-combined_df['MPa'].isna()&800>combined_df['MPa']] #Filtering out samples with very small defects\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'task' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "path = '/mnt/vstor/CSE_MSE_RXF131/cradle-members/mds3/aml334/mds3-advman-2/topics/aml-fractography/sam'\n",
    "sys.path.append(path)\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "import urllib.request\n",
    "\n",
    "sam_checkpoint = path +\"/sam_vit_h_4b8939.pth\"\n",
    "# url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\"\n",
    "# sam_checkpoint = urllib.request.urlretrieve(url)\n",
    "\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "def show_mask(mask, ax, random_color=False, borders = True):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask_image =  mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    if borders:\n",
    "        import cv2\n",
    "        contours, _ = cv2.findContours(mask,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "        # Try to smooth contours\n",
    "        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2) \n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))    \n",
    "\n",
    "def show_masks(image, masks, scores, point_coords=None, box_coords=None, input_labels=None, borders=True):\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(image)\n",
    "        show_mask(mask, plt.gca(), borders=borders)\n",
    "        if point_coords is not None:\n",
    "            assert input_labels is not None\n",
    "            show_points(point_coords, input_labels, plt.gca())\n",
    "        if box_coords is not None:\n",
    "            # boxes\n",
    "            show_box(box_coords, plt.gca())\n",
    "        if len(scores) > 1:\n",
    "            plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "#sys.path.append('/mnt/vstor/CSE_MSE_RXF131/cradle-members/mds3/aml334/mds3-advman-2/packages/') #This was moved to the same repo\n",
    "from organize_data import is_binary, size,size_red, is_greyscale, is_8bit, valid_image\n",
    "\n",
    "#Define metric functions\n",
    "def perimeter_coverage(mask):\n",
    "    # Get the dimensions of the mask\n",
    "    height, width = mask.shape\n",
    "    mask = mask.astype(np.uint8)\n",
    "    if(np.max(mask)!=255):\n",
    "        mask = mask*255\n",
    "    # Extract the perimeter: first and last rows, and first and last columns\n",
    "    perimeter_pixels = np.concatenate([\n",
    "        mask[0, :],  # Top row\n",
    "        mask[-1, :],  # Bottom row\n",
    "        mask[0:-1, 0],  # Left column\n",
    "        mask[0:-1, -1]  # Right column\n",
    "    ])\n",
    "    if(mask.dtype==np.uint8):\n",
    "        max_size=2**8 -1\n",
    "    elif(mask.dtype==np.uint16):\n",
    "        max_size=2**16 -1\n",
    "    elif(mask.dtype==np.uint32):\n",
    "        max_size=2**32 -1\n",
    "    elif(mask.dtype==np.uint64):\n",
    "        max_size=2**64 -1\n",
    "    elif(mask.dtype==np.float16 or mask.dtype==np.float32 or mask.dtype==np.float64):\n",
    "        max_size=2**32 -1\n",
    "    else:\n",
    "        raise TypeError('Mask must be an unsigned interger or float. Was type:'+str(mask.dtype))\n",
    "\n",
    "    # Total perimeter pixels\n",
    "    total_perimeter_pixels = len(perimeter_pixels)*max_size\n",
    "\n",
    "    # Count how many of those pixels are part of the mask (assuming mask is binary 1/0)\n",
    "    covered_perimeter_pixels = np.sum(perimeter_pixels)\n",
    "\n",
    "    # Calculate the percentage of the perimeter covered by the mask\n",
    "    coverage_ratio = covered_perimeter_pixels / total_perimeter_pixels if total_perimeter_pixels != 0 else 0\n",
    "\n",
    "    return coverage_ratio\n",
    "\n",
    "#From Claude 3.5 Connet Oct.24, 2024\n",
    "def unfilled_ratio(img):\n",
    "    if img.dtype != np.uint8:\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "    # Apply threshold to get binary image\n",
    "    _, binary = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return 0\n",
    "    \n",
    "    # Find the largest contour (assuming it's the main object)\n",
    "    main_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Calculate total area within the outer contour\n",
    "    total_area = cv2.contourArea(main_contour)\n",
    "\n",
    "    # Calculate area of holes\n",
    "    holes_area = 0\n",
    "    print(len(contours))\n",
    "    if hierarchy is not None:\n",
    "        for i, h in enumerate(hierarchy[0]):\n",
    "            # If this contour has a parent (meaning it's a hole)\n",
    "            if h[3] >= 0:  # h[3] is the index of the parent contour\n",
    "                holes_area += cv2.contourArea(contours[i])\n",
    "    \n",
    "    # Calculate ratio\n",
    "    if total_area == 0:\n",
    "        return 0\n",
    "    print('total area: '+str(total_area))\n",
    "    print('holes area: '+str(holes_area))\n",
    "    unfilled_ratio = holes_area / total_area\n",
    "\n",
    "    # # Create visualization\n",
    "    # # visualization = img.copy()\n",
    "    # Draw main contour in green\n",
    "    # cv2.drawContours(visualization, [main_contour], -1, (0, 255, 0), 2)\n",
    "    # # Draw holes in red\n",
    "    # for i, h in enumerate(hierarchy[0]):\n",
    "    #     if h[3] >= 0:  # If it's a hole\n",
    "    #         cv2.drawContours(visualization, [contours[i]], -1, (0, 0, 255), 2)\n",
    "    \n",
    "    # Add text with measurements\n",
    "    # cv2.putText(visualization, f'Total Area: {total_area:.0f}', (10, 30),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    # cv2.putText(visualization, f'Holes Area: {holes_area:.0f}', (10, 60),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    # cv2.putText(visualization, f'Ratio: {fill_ratio:.3f}', (10, 90),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "    # cv2.imshow('fill visualization',visualization)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return unfilled_ratio\n",
    "\n",
    "#Sorting Data\n",
    "combined_df = pd.read_csv('/mnt/vstor/CSE_MSE_RXF131/lab-staging/mds3/AdvManu/fractography/combined_df.csv') # Loading combined_df\n",
    "combined_df = combined_df[-combined_df[task].isna()] # Filtering out those without the tasked image\n",
    "combined_df = combined_df[~combined_df['Sample#'].str.contains('CMU11')] # Filtering out the unpolished samples\n",
    "#combined_df = combined_df[-combined_df['MPa'].isna()&800>combined_df['MPa']] #Filtering out samples with very small defects\n",
    "def print_column_counts(df,example=0):\n",
    "    row_structure = '|{:^50}|{:^10}|{:^10}|{:^10}|{:^15}|'\n",
    "    print(row_structure.format('Column name', 'Nulls','Values','Position','Example'))\n",
    "    i=0\n",
    "    for column in df.columns:\n",
    "        nas = df[column].isna().sum()\n",
    "        print(row_structure.format(column,str(nas),str(len(df[column])-nas),str(i),str(df[column].iloc[example])[0:15]))\n",
    "        i+=1\n",
    "print_column_counts(combined_df)\n",
    "\n",
    "def read_img(inp,column):\n",
    "    input_df = pd.read_csv(inp.iloc[idx][column])\n",
    "    path = input_df.iloc[0]['path']\n",
    "    img = cv2.imread(path) #Read image, is color\n",
    "    try:\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #Convert to Greyscale, removing masks if present\n",
    "    except cv2.error:\n",
    "        pass #It throws a generic error\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB) #Convert back to color\n",
    "    print(path)\n",
    "    print(inp.iloc[idx]['MPa'])\n",
    "    return img\n",
    "\n",
    "idx=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive SAM\n",
    "This section was used for looking at how the SAM model deals with individual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '…' (U+2026) (2475387070.py, line 162)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 162\u001b[0;36m\u001b[0m\n\u001b[0;31m    …\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '…' (U+2026)\n"
     ]
    }
   ],
   "source": [
    "idx += 1\n",
    "d_pos = .3\n",
    "grid_spacing = 32\n",
    "RANDOM_POSITIONS=20\n",
    "task='path_initiation'\n",
    "input_size = 1024\n",
    "\n",
    "\n",
    "all_points = []\n",
    "input_label = []\n",
    "image = read_img(combined_df,task)\n",
    "image = cv2.resize(image,(input_size,input_size), interpolation = cv2.INTER_AREA)\n",
    "if(input_size==1024):\n",
    "    image = image[0:960,:]\n",
    "    input_size = 960\n",
    "image_blurred = cv2.blur(cv2.blur(image,(6,6)),(10,10))\n",
    "all_points = []\n",
    "input_label = []\n",
    "\n",
    "#Remove reflective edges\n",
    "condition_img = image_blurred>253\n",
    "non_zero_indices = np.nonzero(np.where(condition_img,1,0))\n",
    "if len(non_zero_indices[0]) > 0:\n",
    "    for i in range(RANDOM_POSITIONS):\n",
    "        temp_idx = int(random.random()*len(non_zero_indices[0]))\n",
    "        all_points.append([non_zero_indices[1][temp_idx],non_zero_indices[0][temp_idx]])\n",
    "        input_label.append(0)\n",
    "    #Removed whited out regions\n",
    "    condition_img = i\n",
    "    # Invert the flood-filled image\n",
    "    filled_mask_inv = cv2.bitwise_not(filled_mask)\n",
    "    \n",
    "    # Combine the original mask with the filled holes\n",
    "    out_mask = binary_mask | filled_mask_inv\n",
    "    \n",
    "    return out_mask\n",
    "max_mask = fill_mask_holes(processed_mask)\n",
    "\n",
    "# plt.axis('on')\n",
    "fig_segment_main_area.show()mage_blurred==0\n",
    "non_zero_indices = np.nonzero(np.where(condition_img,1,0))\n",
    "if len(non_zero_indices[0]) > 0:\n",
    "    for i in range(RANDOM_POSITIONS):\n",
    "        temp_idx = int(random.random()*len(non_zero_indices[0]))\n",
    "        all_points.append([non_zero_indices[1][temp_idx],non_zero_indices[0][temp_idx]])\n",
    "        input_label.append(0)\n",
    "\n",
    "x_mid = image.shape[-2]/2\n",
    "y_mid = image.shape[-3]/2\n",
    "d_disp = math.sqrt((x_mid**2)+(y_mid**2))*d_pos\n",
    "x_disp = math.sin(math.radians(45))*d_disp\n",
    "y_disp = math.cos(math.radians(45))*d_disp\n",
    "\n",
    "#Add positive prompt to center\n",
    "for x_pos in [x_mid - x_disp,x_mid,x_mid+x_disp]:\n",
    "    for y_pos in [y_mid - y_disp,y_mid,y_mid+y_disp]:\n",
    "        all_points.append([x_pos,y_pos])\n",
    "        input_label.append(1)\n",
    "# Add negative prompt on the bottom\n",
    "# for x_pos in [*range(0,input_size+32,32)]:\n",
    "#         all_points.append([x_pos,input_size*.97])\n",
    "#         input_label.append(0)\n",
    "\n",
    "\n",
    "predictor.set_image(image_blurred)\n",
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=np.array(all_points),\n",
    "    point_labels=np.array(input_label),\n",
    "    multimask_out\n",
    "    # Invert the flood-filled image\n",
    "    filled_mask_inv = cv2.bitwise_not(filled_mask)\n",
    "    \n",
    "    # Combine the original mask with the filled holes\n",
    "    out_mask = binary_mask | filled_mask_inv\n",
    "    \n",
    "    return out_mask\n",
    "max_mask = fill_mask_holes(processed_mask)\n",
    "\n",
    "# plt.axis('on')\n",
    "fig_segment_main_area.show()put=True,\n",
    "    \n",
    ")\n",
    "sorted_ind = np.argsort(scores)[::-1]\n",
    "masks = masks[sorted_ind]\n",
    "scores = scores[sorted_ind]\n",
    "logits = logits[sorted_ind]\n",
    "\n",
    "def find_area(mask):\n",
    "    total = 1\n",
    "    for i in mask.shape:\n",
    "        total = total*i\n",
    "    return np.sum(mask) / total\n",
    "masks_area = []\n",
    "for i in masks:\n",
    "    masks_area.append(find_area(i))\n",
    "max_idx = masks_area.index(max(masks_area))\n",
    "\n",
    "processed_mask = (masks[max_idx]).astype(np.uint8) * 255\n",
    "\n",
    "# Step 1: Label connected components\n",
    "num_labels, labels_im = cv2.connectedComponents(processed_mask)\n",
    "\n",
    "# Step 2: Count pixels for each label\n",
    "sizes = np.bincount(labels_im.ravel())\n",
    "\n",
    "# Step 3: Find the largest component (ignore the background)\n",
    "largest_component_label = sizes[1:].argmax() + 1  # +1 to offset background\n",
    "\n",
    "# Step 4: Create a new mask for the largest component\n",
    "largest_defect_mask = np.zeros_like(processed_mask)\n",
    "largest_defect_mask[labels_im == largest_component_label] = 255\n",
    "processed_mask = largest_defect_mask\n",
    "# Creating kernel \n",
    "dilate_kernel = np.ones((6, 6), np.uint8)\n",
    "erosion_kernal = np.ones((6, 6), np.uint8)\n",
    "# Using cv2.erode() method  \n",
    "processed_mask = cv2.dilate(processed_mask, dilate_kernel, cv2.BORDER_REFLECT) #\n",
    "# processed_mask = cv2.dilate(processed_mask, dilate_kernel, cv2.BORDER_REFLECT) #\n",
    "# processed_mask = cv2.dilate(processed_mask, dilate_kernel, cv2.BORDER_REFLECT) #\n",
    "processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "processed_mask = cv2.dilate(processed_mask, np.ones((30, 30), np.uint8), cv2.BORDER_REFLECT) #\n",
    "\n",
    "# fill_mask_holes from Claude 3.5 Sonnet Oct. 23, 2024\n",
    "def fill_mask_holes(mask):\n",
    "    \"\"\"\n",
    "    Fill holes in a binary mask using floodFill.\n",
    "    \n",
    "    Parameters:\n",
    "    mask (numpy.ndarray): Binary input mask (0 and 255 values)\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Mask with holes filled\n",
    "    \"\"\"\n",
    "    # Ensure mask is binary and of type uint8\n",
    "    if mask.dtype != np.uint8:\n",
    "        mask = mask.astype(np.uint8)\n",
    "    \n",
    "    # Threshold to ensure binary image\n",
    "    _, binary_mask = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Create a copy of the mask for flood filling\n",
    "    # Note: floodFill needs a mask that's 2 pixels bigger in each direction\n",
    "    h, w = binary_mask.shape\n",
    "    filled_mask = binary_mask.copy()\n",
    "    filling_mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "    \n",
    "    # Flood fill from point (0,0)\n",
    "    cv2.floodFill(filled_mask, filling_mask, (0,0), 255)\n",
    "    \n",
    "    # Invert the flood-filled image\n",
    "    filled_mask_inv = cv2.bitwise_not(filled_mask)\n",
    "    \n",
    "    # Combine the original mask with the filled holes\n",
    "    out_mask = binary_mask | filled_mask_inv\n",
    "    \n",
    "    return out_mask\n",
    "max_mask = fill_mask_holes(processed_mask)\n",
    "\n",
    "# plt.axis('on')\n",
    "fig_segment_main_area.show()\n",
    "    # Invert the flood-filled image\n",
    "    filled_mask_inv = cv2.bitwise_not(filled_mask)\n",
    "    \n",
    "    # Combine the original mask with the filled holes\n",
    "    out_mask = binary_mask | filled_mask_inv\n",
    "    \n",
    "    return out_mask\n",
    "max_mask = fill_mask_holes(processed_mask)\n",
    "# max_mask = processed_mask\n",
    "all_points_processed = []\n",
    "input_label_processed = []\n",
    "for x_pos in [*range(0,input_size-1,grid_spacing)]:\n",
    "    for y_pos in [*range(0,input_size-1,grid_spacing)]:\n",
    "        if(processed_mask[x_pos,y_pos]!=0):\n",
    "            all_points_processed.append([y_pos,x_pos])\n",
    "            input_label_processed.append(1)            \n",
    "\n",
    "predictor.set_image(image)\n",
    "masks_processed, scores_processed, logits_processed = predictor.predict(\n",
    "    point_coords=np.array(all_points_processed),\n",
    "    point_labels=np.array(input_label_processed),\n",
    "    multimask_output=True,\n",
    ")\n",
    "sorted_ind = np.argsort(scores_processed)[::-1]\n",
    "masks_processed = masks_processed[sorted_ind]\n",
    "scores_processed = scores_processed[sorted_ind]\n",
    "logits_processed = logits_processed[sorted_ind]\n",
    "\n",
    "#Visualization\n",
    "show_masks(image_blurred, masks, scores, point_coords=np.array(all_points), input_labels=np.array(input_label), borders=True)\n",
    "#show_masks(image, masks_processed, scores_processed, input_labels=np.array(input_label_processed), borders=True)\n",
    "fig_segment_main_area,ax = plt.subplots(ncols=3,nrows=3,figsize=(15,15))\n",
    "\n",
    "title = 'Surface Prompts'\n",
    "ax[0,0].set_title(title)\n",
    "ax[0,0].imshow(image_blurred)\n",
    "show_points(np.array(all_points), np.array(input_label), ax[0,0])\n",
    "\n",
    "title = 'Surface SAM Output'+ '\\nPerimeter: '+str(perimeter_coverage(masks[max_idx]))[0:7] +'\\nRatio: '+str(unfilled_ratio(masks[max_idx]))[0:7]\n",
    "ax[0,1].set_title(title)\n",
    "ax[0,1].imshow(masks[max_idx],cmap='gray')\n",
    "\n",
    "title = 'Surface SAM Processed'+ '\\nPerimeter: '+str(perimeter_coverage(max_mask))[0:7]+'\\nRatio: '+str(unfilled_ratio(max_mask))[0:7]\n",
    "ax[0,2].set_title(title)\n",
    "ax[0,2].imshow(max_mask,cmap='gray')\n",
    "\n",
    "title = 'Raw image'\n",
    "ax[1,0].set_title(title)\n",
    "ax[1,0].imshow(image,cmap='gray')\n",
    "\n",
    "title = 'Defect Processing'\n",
    "ax[1,1].set_title(title)\n",
    "ax[1,1].imshow(image,cmap='gray')\n",
    "show_points(np.array(all_points_processed), np.array(input_label_processed), ax[1,1])\n",
    "\n",
    "ax[1,2].set_title('Empty')\n",
    "\n",
    "title = 'Defect Mask 1'+ '\\nPerimeter: '+str(perimeter_coverage(masks_processed[0]))[0:7]+'\\nRatio: '+str(unfilled_ratio(masks_processed[0]))[0:7]\n",
    "ax[2,0].set_title(title)\n",
    "ax[2,0].imshow(masks_processed[0],cmap='gray')\n",
    "\n",
    "title = 'Defect Mask 2'+ '\\nPerimeter: '+str(perimeter_coverage(masks_processed[1]))[0:7]+'\\nRatio: '+str(unfilled_ratio(masks_processed[1]))[0:7]\n",
    "ax[2,1].set_title(title)\n",
    "ax[2,1].imshow(masks_processed[1],cmap='gray')\n",
    "\n",
    "title = 'Defect Mask 3'+ '\\nPerimeter: '+str(perimeter_coverage(masks_processed[2]))[0:7]+'\\nRatio: '+str(unfilled_ratio(masks_processed[2]))[0:7]\n",
    "ax[2,2].set_title(title)\n",
    "ax[2,2].imshow(masks_processed[2],cmap='gray')\n",
    "\n",
    "# plt.axis('on')\n",
    "fig_segment_main_area.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (227286176.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 31\u001b[0;36m\u001b[0m\n\u001b[0;31m    filled_mask_inv = cv2.bitwise_not(filled_mask)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "idx += 1\n",
    "d_pos = .3\n",
    "grid_spacing = 32\n",
    "RANDOM_POSITIONS=20\n",
    "task='path_initiation'\n",
    "input_size = 1024\n",
    "save_path = '/home/aml334/CSE_MSE_RXF131/staging/mds3/fractography/SAM_initiating_defect'\n",
    "\n",
    "all_points = []\n",
    "input_label = []\n",
    "image = read_img(combined_df,task)\n",
    "image = cv2.resize(image,(input_size,input_size), interpolation = cv2.INTER_AREA)\n",
    "if(input_size==1024):\n",
    "    image = image[0:960,:]\n",
    "    input_size = 960\n",
    "image_blurred = cv2.blur(cv2.blur(image,(6,6)),(10,10))\n",
    "all_points = []\n",
    "input_label = []\n",
    "\n",
    "#Remove reflective edges\n",
    "condition_img = image_blurred>253\n",
    "non_zero_indices = np.nonzero(np.where(condition_img,1,0))\n",
    "if len(non_zero_indices[0]) > 0:\n",
    "    for i in range(RANDOM_POSITIONS):\n",
    "        temp_idx = int(random.random()*len(non_zero_indices[0]))\n",
    "        all_points.append([non_zero_indices[1][temp_idx],non_zero_indices[0][temp_idx]])\n",
    "        input_label.append(0)\n",
    "\n",
    "fig_segment_main_area.show()mage_blurred==0\n",
    "non_zero_indices = np.nonzero(np.where(condition_img,1,0))\n",
    "if len(non_zero_indices[0]) > 0:\n",
    "    for i in range(RANDOM_POSITIONS):\n",
    "        temp_idx = int(random.random()*len(non_zero_indices[0]))\n",
    "        all_points.append([non_zero_indices[1][temp_idx],non_zero_indices[0][temp_idx]])\n",
    "        input_label.append(0)\n",
    "\n",
    "x_mid = image.shape[-2]/2\n",
    "y_mid = image.shape[-3]/2\n",
    "d_disp = math.sqrt((x_mid**2)+(y_mid**2))*d_pos\n",
    "x_disp = math.sin(math.radians(45))*d_disp\n",
    "y_disp = math.cos(math.radians(45))*d_disp\n",
    "\n",
    "#Add positive prompt to center\n",
    "for x_pos in [x_mid - x_disp,x_mid,x_mid+x_disp]:\n",
    "    for y_pos in [y_mid - y_disp,y_mid,y_mid+y_disp]:\n",
    "        all_points.append([x_pos,y_pos])\n",
    "        input_label.append(1)\n",
    "# Add negative prompt on the bottom\n",
    "# for x_pos in [*range(0,input_size+32,32)]:\n",
    "#         all_points.append([x_pos,input_size*.97])\n",
    "#         input_label.append(0)\n",
    "\n",
    "\n",
    "predictor.set_image(image_blurred)\n",
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=np.array(all_points),\n",
    "    point_labels=np.array(input_label),\n",
    "    multimask_out=True)\n",
    "    # Invert the flood-filled image\n",
    "    filled_mask_inv = cv2.bitwise_not(filled_mask)\n",
    "    \n",
    "    # Combine the original mask with the filled holes\n",
    "    out_mask = binary_mask | filled_mask_inv\n",
    "    \n",
    "    return out_mask\n",
    "max_mask = fill_mask_holes(processed_mask)\n",
    "…\n",
    "# plt.axis('on')\n",
    "fig_segment_main_area.show()\n",
    "sorted_ind = np.argsort(scores)[::-1]\n",
    "masks = masks[sorted_ind]\n",
    "scores = scores[sorted_ind]\n",
    "logits = logits[sorted_ind]\n",
    "\n",
    "def find_area(mask):\n",
    "    total = 1\n",
    "    for i in mask.shape:\n",
    "        total = total*i\n",
    "    return np.sum(mask) / total\n",
    "masks_area = []\n",
    "for i in masks:\n",
    "    masks_area.append(find_area(i))\n",
    "max_idx = masks_area.index(max(masks_area))\n",
    "\n",
    "processed_mask = (masks[max_idx]).astype(np.uint8) * 255\n",
    "\n",
    "# Step 1: Label connected components\n",
    "num_labels, labels_im = cv2.connectedComponents(processed_mask)\n",
    "\n",
    "# Step 2: Count pixels for each label\n",
    "sizes = np.bincount(labels_im.ravel())\n",
    "\n",
    "# Step 3: Find the largest component (ignore the background)\n",
    "largest_component_label = sizes[1:].argmax() + 1  # +1 to offset background\n",
    "\n",
    "# Step 4: Create a new mask for the largest component\n",
    "largest_defect_mask = np.zeros_like(processed_mask)\n",
    "largest_defect_mask[labels_im == largest_component_label] = 255\n",
    "processed_mask = largest_defect_mask\n",
    "# Creating kernel \n",
    "dilate_kernel = np.ones((6, 6), np.uint8)\n",
    "erosion_kernal = np.ones((6, 6), np.uint8)\n",
    "# Using cv2.erode() method  \n",
    "processed_mask = cv2.dilate(processed_mask, dilate_kernel, cv2.BORDER_REFLECT) #\n",
    "# processed_mask = cv2.dilate(processed_mask, dilate_kernel, cv2.BORDER_REFLECT) #\n",
    "# processed_mask = cv2.dilate(processed_mask, dilate_kernel, cv2.BORDER_REFLECT) #\n",
    "processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "processed_mask = cv2.dilate(processed_mask, np.ones((30, 30), np.uint8), cv2.BORDER_REFLECT) #\n",
    "\n",
    "# fill_mask_holes from Claude 3.5 Sonnet Oct. 23, 2024\n",
    "def fill_mask_holes(mask):\n",
    "    \"\"\"\n",
    "    Fill holes in a binary mask using floodFill.\n",
    "    \n",
    "    Parameters:\n",
    "    mask (numpy.ndarray): Binary input mask (0 and 255 values)\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Mask with holes filled\n",
    "    \"\"\"\n",
    "    # Ensure mask is binary and of type uint8\n",
    "    if mask.dtype != np.uint8:\n",
    "        mask = mask.astype(np.uint8)\n",
    "    \n",
    "    # Threshold to ensure binary image\n",
    "    _, binary_mask = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Create a copy of the mask for flood filling\n",
    "    # Note: floodFill needs a mask that's 2 pixels bigger in each direction\n",
    "    h, w = binary_mask.shape\n",
    "    filled_mask = binary_mask.copy()\n",
    "    filling_mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "    \n",
    "    # Flood fill from point (0,0)\n",
    "    cv2.floodFill(filled_mask, filling_mask, (0,0), 255)\n",
    "    \n",
    "    # Invert the flood-filled image\n",
    "    filled_mask_inv = cv2.bitwise_not(filled_mask)\n",
    "    \n",
    "    # Combine the original mask with the filled holes\n",
    "    out_mask = binary_mask | filled_mask_inv\n",
    "    \n",
    "    return out_mask\n",
    "max_mask = fill_mask_holes(processed_mask)\n",
    "…\n",
    "# plt.axis('on')\n",
    "fig_segment_main_area.show()\n",
    "    # Invert the flood-filled image\n",
    "    filled_mask_inv = cv2.bitwise_not(filled_mask)\n",
    "    \n",
    "    # Combine the original mask with the filled holes\n",
    "    out_mask = binary_mask | filled_mask_inv\n",
    "    \n",
    "    return out_mask\n",
    "max_mask = fill_mask_holes(processed_mask)\n",
    "# max_mask = processed_mask\n",
    "all_points_processed = []\n",
    "input_label_processed = []\n",
    "for x_pos in [*range(0,input_size-1,grid_spacing)]:\n",
    "    for y_pos in [*range(0,input_size-1,grid_spacing)]:\n",
    "        if(processed_mask[x_pos,y_pos]!=0):\n",
    "            all_points_processed.append([y_pos,x_pos])\n",
    "            input_label_processed.append(1)            \n",
    "\n",
    "predictor.set_image(image)\n",
    "masks_processed, scores_processed, logits_processed = predictor.predict(\n",
    "    point_coords=np.array(all_points_processed),\n",
    "    point_labels=np.array(input_label_processed),\n",
    "    multimask_output=True,\n",
    ")\n",
    "sorted_ind = np.argsort(scores_processed)[::-1]\n",
    "masks_processed = masks_processed[sorted_ind]\n",
    "scores_processed = scores_processed[sorted_ind]\n",
    "logits_processed = logits_processed[sorted_ind]\n",
    "\n",
    "#Visualization\n",
    "show_masks(image_blurred, masks, scores, point_coords=np.array(all_points), input_labels=np.array(input_label), borders=True)\n",
    "#show_masks(image, masks_processed, scores_processed, input_labels=np.array(input_label_processed), borders=True)\n",
    "fig_segment_main_area,ax = plt.subplots(ncols=3,nrows=3,figsize=(15,15))\n",
    "\n",
    "title = 'Surface Prompts'\n",
    "ax[0,0].set_title(title)\n",
    "ax[0,0].imshow(image_blurred)\n",
    "show_points(np.array(all_points), np.array(input_label), ax[0,0])\n",
    "\n",
    "title = 'Surface SAM Output'+ '\\nPerimeter: '+str(perimeter_coverage(masks[max_idx]))[0:7] +'\\nRatio: '+str(unfilled_ratio(masks[max_idx]))[0:7]\n",
    "ax[0,1].set_title(title)\n",
    "ax[0,1].imshow(masks[max_idx],cmap='gray')\n",
    "\n",
    "title = 'Surface SAM Processed'+ '\\nPerimeter: '+str(perimeter_coverage(max_mask))[0:7]+'\\nRatio: '+str(unfilled_ratio(max_mask))[0:7]\n",
    "ax[0,2].set_title(title)\n",
    "ax[0,2].imshow(max_mask,cmap='gray')\n",
    "\n",
    "title = 'Raw image'\n",
    "ax[1,0].set_title(title)\n",
    "ax[1,0].imshow(image,cmap='gray')\n",
    "\n",
    "title = 'Defect Processing'\n",
    "ax[1,1].set_title(title)\n",
    "ax[1,1].imshow(image,cmap='gray')\n",
    "show_points(np.array(all_points_processed), np.array(input_label_processed), ax[1,1])\n",
    "\n",
    "ax[1,2].set_title('Empty')\n",
    "\n",
    "title = 'Defect Mask 1'+ '\\nPerimeter: '+str(perimeter_coverage(masks_processed[0]))[0:7]+'\\nRatio: '+str(unfilled_ratio(masks_processed[0]))[0:7]\n",
    "ax[2,0].set_title(title)\n",
    "ax[2,0].imshow(masks_processed[0],cmap='gray')\n",
    "\n",
    "title = 'Defect Mask 2'+ '\\nPerimeter: '+str(perimeter_coverage(masks_processed[1]))[0:7]+'\\nRatio: '+str(unfilled_ratio(masks_processed[1]))[0:7]\n",
    "ax[2,1].set_title(title)\n",
    "ax[2,1].imshow(masks_processed[1],cmap='gray')\n",
    "\n",
    "title = 'Defect Mask 3'+ '\\nPerimeter: '+str(perimeter_coverage(masks_processed[2]))[0:7]+'\\nRatio: '+str(unfilled_ratio(masks_processed[2]))[0:7]\n",
    "ax[2,2].set_title(title)\n",
    "ax[2,2].imshow(masks_processed[2],cmap='gray')\n",
    "\n",
    "# plt.axis('on')\n",
    "fig_segment_main_area.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is measuring how the pipeline performs on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to expression here. Maybe you meant '==' instead of '='? (3327547643.py, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 46\u001b[0;36m\u001b[0m\n\u001b[0;31m    im/home/aml334/CSE_MSE_RXF131/staging/mds3/fractography/SAM_initiating_defectage = read_img(combined_df,task)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "idx -=1\n",
    "d_pos = .3\n",
    "grid_spacing = 32\n",
    "RANDOM_POSITIONS=20\n",
    "task='path_initiation'\n",
    "input_size = 1024\n",
    "\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('/mnt/vstor/CSE_MSE_RXF131/cradle-members/mds3/aml334/mds3-advman-2/packages/AdvSegLearn/Usage') #edited to work with Jupyter notebooks\n",
    "from organize_data import is_binary, size,size_red, is_greyscale, is_8bit, valid_image\n",
    "\n",
    "#Sorting Data\n",
    "combined_df = pd.read_csv('/mnt/vstor/CSE_MSE_RXF131/lab-staging/mds3/AdvManu/fractography/combined_df.csv')\n",
    "combined_df = combined_df[-combined_df['path_stitched'].isna()&-combined_df[task].isna()&~combined_df['Sample#'].str.contains('CMU11')]\n",
    "# combined_df = combined_df[-combined_df['MPa'].isna()&800>combined_df['MPa']]\n",
    "def print_column_counts(df,example=0):\n",
    "    row_structure = '|{:^50}|{:^10}|{:^10}|{:^10}|{:^15}|'\n",
    "    print(row_structure.format('Column name', 'Nulls','Values','Position','Example'))\n",
    "    i=0\n",
    "    for column in df.columns:\n",
    "        nas = df[column].isna().sum()\n",
    "        print(row_structure.format(column,str(nas),str(len(df[column])-nas),str(i),str(df[column].iloc[example])[0:15]))\n",
    "        i+=1\n",
    "print_column_counts(combined_df)\n",
    "\n",
    "\n",
    "idx_range = [*range(0,len(combined_df[task]))]\n",
    "for i in idx_range:\n",
    "    all_points = []\n",
    "    input_label = []\n",
    "    def read_img(inp,column):\n",
    "        input_df = pd.read_csv(inp.iloc[idx][column])\n",
    "        path = input_df.iloc[0]['path']\n",
    "        img = cv2.imread(path)\n",
    "        print(path)\n",
    "        print(inp.iloc[idx]['MPa'])\n",
    "        return img\n",
    "    im/home/aml334/CSE_MSE_RXF131/staging/mds3/fractography/SAM_initiating_defectage = read_img(combined_df,task)\n",
    "    image = cv2.resize(image,(input_size,input_size), interpolation = cv2.INTER_AREA)\n",
    "    if(input_size==1024):\n",
    "        image = image[0:960,:]\n",
    "        input_size = 960\n",
    "    image_blurred = cv2.blur(cv2.blur(image,(6,6)),(10,10))\n",
    "    all_points = []\n",
    "    input_label = []\n",
    "\n",
    "    #Remove reflective edges\n",
    "    condition_img = image_blurred>253\n",
    "    non_zero_indices = np.nonzero(np.where(condition_img,1,0))\n",
    "    if len(non_zero_indices[0]) > 0:\n",
    "        for i in range(RANDOM_POSITIONS):\n",
    "            temp_idx = int(random.random()*len(non_zero_indices[0]))\n",
    "            all_points.append([non_zero_indices[1][temp_idx],non_zero_indices[0][temp_idx]])\n",
    "            input_label.append(0)\n",
    "    #Removed whited out regions\n",
    "    condition_img = image_blurred==0\n",
    "    non_zero_indices = np.nonzero(np.where(condition_img,1,0))\n",
    "    if len(non_zero_indices[0]) > 0:\n",
    "        for i in range(RANDOM_POSITIONS):\n",
    "            temp_idx = int(random.random()*len(non_zero_indices[0]))\n",
    "            all_points.append([non_zero_indices[1][temp_idx],non_zero_indices[0][temp_idx]])\n",
    "            input_label.append(0)\n",
    "\n",
    "    x_mid = image.shape[0]/2\n",
    "    y_mid = image.shape[-1]/2\n",
    "    d_disp = math.sqrt((x_mid**2)+(y_mid**2))*d_pos\n",
    "    x_disp = math.sin(math.radians(45))*d_disp\n",
    "    y_disp = math.cos(math.radians(45))*d_disp\n",
    "\n",
    "    #Add positive prompt to center\n",
    "    for x_pos in [x_mid - x_disp,x_mid,x_mid+x_disp]:\n",
    "        for y_pos in [y_mid - y_disp,y_mid,y_mid+y_disp]:\n",
    "            all_points.append([x_pos,y_pos])\n",
    "            input_label.append(1)\n",
    "    # Add negative prompt on the bottom\n",
    "    # for x_pos in [*range(0,input_size+32,32)]:\n",
    "    #         all_points.append([x_pos,input_size*.97])\n",
    "    #         input_label.append(0)\n",
    "\n",
    "\n",
    "    predictor.set_image(image_blurred)\n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords=np.array(all_points),\n",
    "        point_labels=np.array(input_label),\n",
    "        multimask_output=True,\n",
    "    )\n",
    "    sorted_ind = np.argsort(scores)[::-1]\n",
    "    masks = masks[sorted_ind]\n",
    "    scores = scores[sorted_ind]\n",
    "    logits = logits[sorted_ind]\n",
    "\n",
    "    def find_area(mask):\n",
    "        total = 1\n",
    "        for i in mask.shape:\n",
    "            total = total*i\n",
    "        return np.sum(mask) / total\n",
    "    masks_area = []\n",
    "    for i in masks:\n",
    "        masks_area.append(find_area(i))\n",
    "    max_idx = masks_area.index(max(masks_area))\n",
    "\n",
    "    processed_mask = (masks[max_idx]).astype(np.uint8) * 255\n",
    "    # Creating kernel \n",
    "    dilate_kernel = np.ones((6, 6), np.uint8)\n",
    "    erosion_kernal = np.ones((6, 6), np.uint8)\n",
    "    # Using cv2.erode() method  \n",
    "    processed_mask = cv2.dilate(processed_mask, dilate_kernel, cv2.BORDER_REFLECT) #\n",
    "    # processed_mask = cv2.dilate(processed_mask, dilate_kernel, cv2.BORDER_REFLECT) #\n",
    "    # processed_mask = cv2.dilate(processed_mask, dilate_kernel, cv2.BORDER_REFLECT) #\n",
    "    processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "    processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "    processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "    processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "    processed_mask = cv2.erode(processed_mask, erosion_kernal, cv2.BORDER_REFLECT) \n",
    "    processed_mask = cv2.dilate(processed_mask, np.ones((30, 30), np.uint8), cv2.BORDER_REFLECT) #\n",
    "\n",
    "    # Step 1: Label connected components\n",
    "    num_labels, labels_im = cv2.connectedComponents(processed_mask)\n",
    "\n",
    "    # Step 2: Count pixels for each label\n",
    "    sizes = np.bincount(labels_im.ravel())\n",
    "\n",
    "    # Step 3: Find the largest component (ignore the background)\n",
    "    largest_component_label = sizes[1:].argmax() + 1  # +1 to offset background\n",
    "\n",
    "    # Step 4: Create a new mask for the largest component\n",
    "    largest_defect_mask = np.zeros_like(processed_mask)\n",
    "    largest_defect_mask[labels_im == largest_component_label] = 255\n",
    "    processed_mask = largest_defect_mask\n",
    "\n",
    "    # fill_mask_holes from Claude 3.5 Sonnet Oct. 23, 2024\n",
    "    def fill_mask_holes(mask):\n",
    "        \"\"\"\n",
    "        Fill holes in a binary mask using floodFill.\n",
    "        \n",
    "        Parameters:\n",
    "        mask (numpy.ndarray): Binary input mask (0 and 255 values)\n",
    "        \n",
    "        Returns:\n",
    "        numpy.ndarray: Mask with holes filled\n",
    "        \"\"\"\n",
    "        # Ensure mask is binary and of type uint8\n",
    "        if mask.dtype != np.uint8:\n",
    "            mask = mask.astype(np.uint8)\n",
    "        \n",
    "        # Threshold to ensure binary image\n",
    "        _, binary_mask = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Create a copy of the mask for flood filling\n",
    "        # Note: floodFill needs a mask that's 2 pixels bigger in each direction\n",
    "        h, w = binary_mask.shape\n",
    "        filled_mask = binary_mask.copy()\n",
    "        filling_mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "        \n",
    "        # Flood fill from point (0,0)\n",
    "        cv2.floodFill(filled_mask, filling_mask, (0,0), 255)\n",
    "        \n",
    "        # Invert the flood-filled image\n",
    "        filled_mask_inv = cv2.bitwise_not(filled_mask)\n",
    "        \n",
    "        # Combine the original mask with the filled holes\n",
    "        out_mask = binary_mask | filled_mask_inv\n",
    "        \n",
    "        return out_mask\n",
    "    max_mask = fill_mask_holes(processed_mask)\n",
    "\n",
    "    all_points_processed = []\n",
    "    input_label_processed = []\n",
    "    for x_pos in [*range(0,input_size-1,grid_spacing)]:\n",
    "        for y_pos in [*range(0,input_size-1,grid_spacing)]:\n",
    "            if(processed_mask[x_pos,y_pos]!=0):\n",
    "                all_points_processed.append([y_pos,x_pos])\n",
    "                input_label_processed.append(1)            \n",
    "\n",
    "    predictor.set_image(image)\n",
    "    masks_processed, scores_processed, logits_processed = predictor.predict(\n",
    "        point_coords=np.array(all_points_processed),\n",
    "        point_labels=np.array(input_label_processed),\n",
    "        multimask_output=True,\n",
    "    )\n",
    "    sorted_ind = np.argsort(scores_processed)[::-1]\n",
    "    masks_processed = masks_processed[sorted_ind]\n",
    "    scores_processed = scores_processed[sorted_ind]\n",
    "    logits_processed = logits_processed[sorted_ind]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
